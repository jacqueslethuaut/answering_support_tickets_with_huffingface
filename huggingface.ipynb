{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":16096,"status":"ok","timestamp":1704880198189,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"dxegMUWI_HYo"},"outputs":[],"source":["#!pip install huggingface_hub -q"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting llama-cpp-python\n","  Using cached llama_cpp_python-0.2.28-cp310-cp310-macosx_14_0_arm64.whl\n","Requirement already satisfied: typing-extensions>=4.5.0 in /Users/jacqueslethuaut/.virtualenvs/venv-310-llama/lib/python3.10/site-packages (from llama-cpp-python) (4.9.0)\n","Requirement already satisfied: numpy>=1.20.0 in /Users/jacqueslethuaut/.virtualenvs/venv-310-llama/lib/python3.10/site-packages (from llama-cpp-python) (1.26.3)\n","Requirement already satisfied: diskcache>=5.6.1 in /Users/jacqueslethuaut/.virtualenvs/venv-310-llama/lib/python3.10/site-packages (from llama-cpp-python) (5.6.3)\n","Installing collected packages: llama-cpp-python\n","Successfully installed llama-cpp-python-0.2.28\n"]}],"source":["#!pip install llama-cpp-python\n","!CMAKE_ARGS=\"-DLLAMA_BLAS=ON -DLLAMA_BLAS_VENDOR=OpenBLAS\" pip install llama-cpp-python"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":224,"status":"ok","timestamp":1704880378173,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"Gj5_LOqvxZGc"},"outputs":[],"source":["from huggingface_hub import hf_hub_download\n","from llama_cpp import Llama"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":199,"referenced_widgets":["e1eb7a8885f74a168af943fa0fc136b2","7adc83d68d0a4f5fac68c06d4068a291","86e670e1428648208656b980303b0b9a","97079f3956444e1c8acbffa44952d2ae","d2aff51cf4374a86aa48008ba223d505","12b2a94d9f554cc4a1a2bcee6bedec52","4066d046bbcd468796afd4c81d361d8c","51160d84d8054e5fa8bc717cc8a6fae9","cb8f1e445d884165b4702ca96ca945a0","145639afd05944b0978a932a9833c738","047fc9dc42044a09b524f032c61f6e38"]},"executionInfo":{"elapsed":63489,"status":"ok","timestamp":1704880629256,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"NSsqekpsyOOc","outputId":"c200915e-0c80-43ba-e2ef-75ef7fd13fa8"},"outputs":[],"source":["model_name_or_path = \"TheBloke/Llama-2-13B-chat-GGUF\"\n","model_basename = \"llama-2-13b-chat.Q5_K_M.gguf\"\n","model_path = hf_hub_download(repo_id=model_name_or_path, filename=model_basename)"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45839,"status":"ok","timestamp":1704880902131,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"pKFh3i9tzOjA","outputId":"d8130edb-8b90-4ff0-add8-96ded1489e71"},"outputs":[{"name":"stderr","output_type":"stream","text":["llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from /Users/jacqueslethuaut/.cache/huggingface/hub/models--TheBloke--Llama-2-13B-chat-GGUF/snapshots/4458acc949de0a9914c3eab623904d4fe999050a/llama-2-13b-chat.Q5_K_M.gguf (version GGUF V2)\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  10:                          general.file_type u32              = 17\n","llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n","llama_model_loader: - type  f32:   81 tensors\n","llama_model_loader: - type q5_K:  241 tensors\n","llama_model_loader: - type q6_K:   41 tensors\n","llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n","llm_load_print_meta: format           = GGUF V2\n","llm_load_print_meta: arch             = llama\n","llm_load_print_meta: vocab type       = SPM\n","llm_load_print_meta: n_vocab          = 32000\n","llm_load_print_meta: n_merges         = 0\n","llm_load_print_meta: n_ctx_train      = 4096\n","llm_load_print_meta: n_embd           = 5120\n","llm_load_print_meta: n_head           = 40\n","llm_load_print_meta: n_head_kv        = 40\n","llm_load_print_meta: n_layer          = 40\n","llm_load_print_meta: n_rot            = 128\n","llm_load_print_meta: n_embd_head_k    = 128\n","llm_load_print_meta: n_embd_head_v    = 128\n","llm_load_print_meta: n_gqa            = 1\n","llm_load_print_meta: n_embd_k_gqa     = 5120\n","llm_load_print_meta: n_embd_v_gqa     = 5120\n","llm_load_print_meta: f_norm_eps       = 0.0e+00\n","llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n","llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n","llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n","llm_load_print_meta: n_ff             = 13824\n","llm_load_print_meta: n_expert         = 0\n","llm_load_print_meta: n_expert_used    = 0\n","llm_load_print_meta: rope scaling     = linear\n","llm_load_print_meta: freq_base_train  = 10000.0\n","llm_load_print_meta: freq_scale_train = 1\n","llm_load_print_meta: n_yarn_orig_ctx  = 4096\n","llm_load_print_meta: rope_finetuned   = unknown\n","llm_load_print_meta: model type       = 13B\n","llm_load_print_meta: model ftype      = Q5_K - Medium\n","llm_load_print_meta: model params     = 13.02 B\n","llm_load_print_meta: model size       = 8.60 GiB (5.67 BPW) \n","llm_load_print_meta: general.name     = LLaMA v2\n","llm_load_print_meta: BOS token        = 1 '<s>'\n","llm_load_print_meta: EOS token        = 2 '</s>'\n","llm_load_print_meta: UNK token        = 0 '<unk>'\n","llm_load_print_meta: LF token         = 13 '<0x0A>'\n","llm_load_tensors: ggml ctx size       =    0.14 MiB\n","ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  8802.34 MiB, ( 8802.41 / 16384.02)\n","llm_load_tensors: system memory used  = 8801.77 MiB\n","...................................................................................................\n","llama_new_context_with_model: n_ctx      = 1024\n","llama_new_context_with_model: freq_base  = 10000.0\n","llama_new_context_with_model: freq_scale = 1\n","ggml_metal_init: allocating\n","ggml_metal_init: found device: Apple M2\n","ggml_metal_init: picking default device: Apple M2\n","ggml_metal_init: default.metallib not found, loading from source\n","ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n","ggml_metal_init: loading '/Users/jacqueslethuaut/.virtualenvs/venv-310-llama/lib/python3.10/site-packages/llama_cpp/ggml-metal.metal'\n","ggml_metal_init: GPU name:   Apple M2\n","ggml_metal_init: GPU family: MTLGPUFamilyApple8 (1008)\n","ggml_metal_init: hasUnifiedMemory              = true\n","ggml_metal_init: recommendedMaxWorkingSetSize  = 17179.89 MB\n","ggml_metal_init: maxTransferRate               = built-in GPU\n","ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   800.00 MiB, ( 9603.97 / 16384.02)\n","llama_new_context_with_model: KV self size  =  800.00 MiB, K (f16):  400.00 MiB, V (f16):  400.00 MiB\n","ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 9603.98 / 16384.02)\n","llama_build_graph: non-view tensors processed: 844/844\n","llama_new_context_with_model: compute buffer total size = 3.41 MiB\n","ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.23 MiB, ( 9604.20 / 16384.02)\n","AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"]}],"source":["lcpp_llm = Llama(\n","    model_path=model_path,\n","    n_threads=4,\n","    n_batch=1,\n","    n_gpu_layers=1,\n","    n_ctx=1024\n",")"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":246,"status":"ok","timestamp":1704881526673,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"XmXDNgWf0bw7"},"outputs":[],"source":["def generate_llama_response(support_ticket_text):\n","  system_message = \"\"\"\n","    [INST] «SYS»\n","    Introduction (System Role):\n","    I am the technical assistant designed to guide you in processing support tickets.\n","    Ticket Categorization:\n","    Your primary task is to categorize the support ticket into one of the following categories:\n","    -   Technical Issues\n","    -   Hardware Issues\n","    -   Data Recovery\n","    Response Options:\n","    Please respond with only one of the predefined categories listed above.\n","    Sub-Tasks:\n","    Once the category is identified, perform the following sub-tasks:\n","    -   Creating Tags: Create tags that will help further classify the ticket.\n","    -   Assigning Priority: Assign a priority level (e.g., \"High\" or \"Low\").\n","    -   Suggesting ETA: Provide an estimated time for resolving the issue.\n","    General Instructions:\n","    -   Categorization: Categorize the ticket only into the predefined categories.\n","    -   Reading Carefully: Read the support ticket text thoroughly and respond accordingly.\n","    Output Format:\n","    Please provide the response in the following structured format:\n","    Category: [Your Category Here]\n","    Tags: [Your Tags Here]\n","    Priority: [Your Priority Level Here]\n","    ETA: [Your Estimated Time Here]\n","    «/SYS» [/INST]\n","    \"\"\"\n","\n","\n","  #  Combine user_prompt and system_message to create the prompt\n","  prompt = f\"{support_ticket_text}\\n{system_message}\"\n","\n","  #  Generate a response from the LLaMA model\n","  response = lcpp_llm(\n","    prompt=prompt,\n","    max_tokens=256,                  # Set the max tokens to generate\n","    temperature=0.0,                  # Set the temperature (between 0 and 1)\n","    top_p=0.95,\n","    repeat_penalty=1.2,\n","    top_k=50,\n","    stop=['INST'],\n","    echo=False\n","  )\n","  #  Extract and return the response text\n","  response_text = response[\"choices\"][0][\"text\"]\n","  return response_text\n"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17484,"status":"ok","timestamp":1704881566410,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"ak7_DC4p257_","outputId":"fdb280b9-f703-4aae-ffaf-9a85b0524cf3"},"outputs":[],"source":["import pandas as pd\n"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":527,"status":"ok","timestamp":1704881813154,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"Yx78I3SE3B1L"},"outputs":[],"source":["data = pd.read_csv('support_ticket_data.csv')"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"elapsed":238,"status":"ok","timestamp":1704881825464,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"ogEkHHUh4B6u","outputId":"d80eab86-d7c6-4395-cc88-4bb7537bceff"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>support_tick_id</th>\n","      <th>support_ticket_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ST2023-006</td>\n","      <td>My internet connection has significantly slowe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ST2023-007</td>\n","      <td>Urgent help required! My laptop refuses to sta...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ST2023-008</td>\n","      <td>I've accidentally deleted essential work docum...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ST2023-009</td>\n","      <td>Despite being in close proximity to my Wi-Fi r...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ST2023-010</td>\n","      <td>My smartphone battery is draining rapidly, eve...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  support_tick_id                                support_ticket_text\n","0      ST2023-006  My internet connection has significantly slowe...\n","1      ST2023-007  Urgent help required! My laptop refuses to sta...\n","2      ST2023-008  I've accidentally deleted essential work docum...\n","3      ST2023-009  Despite being in close proximity to my Wi-Fi r...\n","4      ST2023-010  My smartphone battery is draining rapidly, eve..."]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1704881838089,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"x5R6W4hh4EFy","outputId":"63faf6f3-55c1-40ce-88c5-2bf138ba77ac"},"outputs":[{"data":{"text/plain":["(21, 2)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["data.shape"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1704881862156,"user":{"displayName":"jacques le thuaut","userId":"00318315986116963344"},"user_tz":-60},"id":"Q_AEhwGg4GIa","outputId":"4e85fedc-8385-406a-9069-ed88d99a07ae"},"outputs":[{"data":{"text/plain":["support_tick_id        0\n","support_ticket_text    0\n","dtype: int64"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["data.isnull().sum()"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"B_QQhWmR4L6c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      15.60 ms /   117 runs   (    0.13 ms per token,  7502.40 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   78682.81 ms /   476 runs   (  165.30 ms per token,     6.05 tokens per second)\n","llama_print_timings:       total time =   79626.70 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =       5.21 ms /    43 runs   (    0.12 ms per token,  8261.29 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   51972.27 ms /   401 runs   (  129.61 ms per token,     7.72 tokens per second)\n","llama_print_timings:       total time =   52523.90 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      32.26 ms /   228 runs   (    0.14 ms per token,  7067.58 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   82229.38 ms /   582 runs   (  141.29 ms per token,     7.08 tokens per second)\n","llama_print_timings:       total time =   83344.52 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      15.18 ms /   107 runs   (    0.14 ms per token,  7051.07 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   70285.30 ms /   469 runs   (  149.86 ms per token,     6.67 tokens per second)\n","llama_print_timings:       total time =   71000.17 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      19.86 ms /   144 runs   (    0.14 ms per token,  7250.39 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  108202.07 ms /   481 runs   (  224.95 ms per token,     4.45 tokens per second)\n","llama_print_timings:       total time =  108983.48 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      27.50 ms /   144 runs   (    0.19 ms per token,  5235.98 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  102920.91 ms /   481 runs   (  213.97 ms per token,     4.67 tokens per second)\n","llama_print_timings:       total time =  103647.49 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      25.77 ms /   183 runs   (    0.14 ms per token,  7101.83 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  117879.10 ms /   523 runs   (  225.39 ms per token,     4.44 tokens per second)\n","llama_print_timings:       total time =  118675.28 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      45.05 ms /   256 runs   (    0.18 ms per token,  5682.45 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  145057.11 ms /   597 runs   (  242.98 ms per token,     4.12 tokens per second)\n","llama_print_timings:       total time =  146188.45 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      42.53 ms /   167 runs   (    0.25 ms per token,  3926.82 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  134676.63 ms /   502 runs   (  268.28 ms per token,     3.73 tokens per second)\n","llama_print_timings:       total time =  135967.16 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      23.00 ms /   132 runs   (    0.17 ms per token,  5738.38 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","Llama.generate: prefix-match hit\n","llama_print_timings:        eval time =  120592.32 ms /   476 runs   (  253.35 ms per token,     3.95 tokens per second)\n","llama_print_timings:       total time =  121926.66 ms\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      22.34 ms /   150 runs   (    0.15 ms per token,  6715.32 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  147970.19 ms /   487 runs   (  303.84 ms per token,     3.29 tokens per second)\n","llama_print_timings:       total time =  149025.32 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      16.39 ms /   136 runs   (    0.12 ms per token,  8297.24 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  108346.32 ms /   477 runs   (  227.14 ms per token,     4.40 tokens per second)\n","llama_print_timings:       total time =  109093.59 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      23.00 ms /   192 runs   (    0.12 ms per token,  8347.46 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  109818.73 ms /   533 runs   (  206.04 ms per token,     4.85 tokens per second)\n","llama_print_timings:       total time =  110502.11 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      20.11 ms /   153 runs   (    0.13 ms per token,  7608.53 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  104368.64 ms /   486 runs   (  214.75 ms per token,     4.66 tokens per second)\n","llama_print_timings:       total time =  104954.99 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      16.19 ms /   128 runs   (    0.13 ms per token,  7906.11 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  101871.87 ms /   466 runs   (  218.61 ms per token,     4.57 tokens per second)\n","llama_print_timings:       total time =  102471.92 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      11.88 ms /   100 runs   (    0.12 ms per token,  8416.80 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =   89598.01 ms /   429 runs   (  208.85 ms per token,     4.79 tokens per second)\n","llama_print_timings:       total time =   90103.48 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      20.45 ms /   150 runs   (    0.14 ms per token,  7333.89 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","Llama.generate: prefix-match hit\n","llama_print_timings:        eval time =  103333.94 ms /   484 runs   (  213.50 ms per token,     4.68 tokens per second)\n","llama_print_timings:       total time =  103954.87 ms\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      26.96 ms /   188 runs   (    0.14 ms per token,  6972.00 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","Llama.generate: prefix-match hit\n","llama_print_timings:        eval time =  116495.34 ms /   517 runs   (  225.33 ms per token,     4.44 tokens per second)\n","llama_print_timings:       total time =  117239.28 ms\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      20.43 ms /   156 runs   (    0.13 ms per token,  7636.20 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  100237.05 ms /   486 runs   (  206.25 ms per token,     4.85 tokens per second)\n","llama_print_timings:       total time =  100848.33 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      13.43 ms /   103 runs   (    0.13 ms per token,  7671.11 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  119750.22 ms /   589 runs   (  203.31 ms per token,     4.92 tokens per second)\n","llama_print_timings:       total time =  120501.68 ms\n","Llama.generate: prefix-match hit\n","\n","llama_print_timings:        load time =   18500.48 ms\n","llama_print_timings:      sample time =      13.70 ms /   107 runs   (    0.13 ms per token,  7811.93 tokens per second)\n","llama_print_timings: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n","llama_print_timings:        eval time =  143835.62 ms /   706 runs   (  203.73 ms per token,     4.91 tokens per second)\n","llama_print_timings:       total time =  144613.52 ms\n"]}],"source":["data['llama_response'] = data['support_ticket_text'].apply(lambda x:generate_llama_response(x))"]},{"cell_type":"code","execution_count":37,"metadata":{"id":"aOu3Cd9P4Ya6"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>support_tick_id</th>\n","      <th>support_ticket_text</th>\n","      <th>llama_response</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ST2023-006</td>\n","      <td>My internet connection has significantly slowe...</td>\n","      <td>Sure, I'd be happy to help! Based on the info...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ST2023-007</td>\n","      <td>Urgent help required! My laptop refuses to sta...</td>\n","      <td>Category: Hardware Issues\\nTags: Laptop, Start...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ST2023-008</td>\n","      <td>I've accidentally deleted essential work docum...</td>\n","      <td>Sure, I can help you with that! Based on your...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ST2023-009</td>\n","      <td>Despite being in close proximity to my Wi-Fi r...</td>\n","      <td>Sure, I can help you with that! Based on the ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ST2023-010</td>\n","      <td>My smartphone battery is draining rapidly, eve...</td>\n","      <td>Sure, I'd be happy to help! Based on the info...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  support_tick_id                                support_ticket_text  \\\n","0      ST2023-006  My internet connection has significantly slowe...   \n","1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n","2      ST2023-008  I've accidentally deleted essential work docum...   \n","3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n","4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n","\n","                                      llama_response  \n","0   Sure, I'd be happy to help! Based on the info...  \n","1  Category: Hardware Issues\\nTags: Laptop, Start...  \n","2   Sure, I can help you with that! Based on your...  \n","3   Sure, I can help you with that! Based on the ...  \n","4   Sure, I'd be happy to help! Based on the info...  "]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["import json"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["def extract_json_data(response_text): \n","    try:\n","        lines = response_text.strip().split('\\n')\n","        response_dict = {line.split(':')[0].strip(): line.split(':')[1].strip() for line in lines if ':' in line}\n","        return response_dict\n","    except json.JSONDecodeError as e: \n","        print(f\"Error parsing JSON: {e}\") \n","        return {}"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>support_tick_id</th>\n","      <th>support_ticket_text</th>\n","      <th>llama_response</th>\n","      <th>llama_response_parsed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ST2023-006</td>\n","      <td>My internet connection has significantly slowe...</td>\n","      <td>Sure, I'd be happy to help! Based on the info...</td>\n","      <td>{'Category': 'Technical Issues', 'Tags': 'Inte...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ST2023-007</td>\n","      <td>Urgent help required! My laptop refuses to sta...</td>\n","      <td>Category: Hardware Issues\\nTags: Laptop, Start...</td>\n","      <td>{'Category': 'Hardware Issues', 'Tags': 'Lapto...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>ST2023-008</td>\n","      <td>I've accidentally deleted essential work docum...</td>\n","      <td>Sure, I can help you with that! Based on your...</td>\n","      <td>{'Here are some sub-tasks to assist me in furt...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ST2023-009</td>\n","      <td>Despite being in close proximity to my Wi-Fi r...</td>\n","      <td>Sure, I can help you with that! Based on the ...</td>\n","      <td>{'Sure, I can help you with that! Based on the...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ST2023-010</td>\n","      <td>My smartphone battery is draining rapidly, eve...</td>\n","      <td>Sure, I'd be happy to help! Based on the info...</td>\n","      <td>{'Category': 'Technical Issues', 'Tags': 'Smar...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  support_tick_id                                support_ticket_text  \\\n","0      ST2023-006  My internet connection has significantly slowe...   \n","1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n","2      ST2023-008  I've accidentally deleted essential work docum...   \n","3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n","4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n","\n","                                      llama_response  \\\n","0   Sure, I'd be happy to help! Based on the info...   \n","1  Category: Hardware Issues\\nTags: Laptop, Start...   \n","2   Sure, I can help you with that! Based on your...   \n","3   Sure, I can help you with that! Based on the ...   \n","4   Sure, I'd be happy to help! Based on the info...   \n","\n","                               llama_response_parsed  \n","0  {'Category': 'Technical Issues', 'Tags': 'Inte...  \n","1  {'Category': 'Hardware Issues', 'Tags': 'Lapto...  \n","2  {'Here are some sub-tasks to assist me in furt...  \n","3  {'Sure, I can help you with that! Based on the...  \n","4  {'Category': 'Technical Issues', 'Tags': 'Smar...  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["data['llama_response_parsed'] = data['llama_response'].apply(extract_json_data) \n","data.head()"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["def normalize_llama_response(response_dict):\n","    # Standardizing keys to lowercase\n","    normalized_response = {key.lower(): value.strip() for key, value in response_dict.items()}\n","\n","    # Handling missing values\n","    for key in ['category', 'tags', 'priority', 'eta']:\n","        if key not in normalized_response:\n","            normalized_response[key] = None  # or any default value you prefer\n","\n","    # Additional normalization can be added here as needed\n","\n","    return normalized_response\n"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["  support_tick_id                                support_ticket_text  \\\n","0      ST2023-006  My internet connection has significantly slowe...   \n","1      ST2023-007  Urgent help required! My laptop refuses to sta...   \n","2      ST2023-008  I've accidentally deleted essential work docum...   \n","3      ST2023-009  Despite being in close proximity to my Wi-Fi r...   \n","4      ST2023-010  My smartphone battery is draining rapidly, eve...   \n","\n","                                      llama_response  \\\n","0   Sure, I'd be happy to help! Based on the info...   \n","1  Category: Hardware Issues\\nTags: Laptop, Start...   \n","2   Sure, I can help you with that! Based on your...   \n","3   Sure, I can help you with that! Based on the ...   \n","4   Sure, I'd be happy to help! Based on the info...   \n","\n","                               llama_response_parsed  \\\n","0  {'Category': 'Technical Issues', 'Tags': 'Inte...   \n","1  {'Category': 'Hardware Issues', 'Tags': 'Lapto...   \n","2  {'Here are some sub-tasks to assist me in furt...   \n","3  {'Sure, I can help you with that! Based on the...   \n","4  {'Category': 'Technical Issues', 'Tags': 'Smar...   \n","\n","                           llama_response_normalized  \n","0  {'category': 'Technical Issues', 'tags': 'Inte...  \n","1  {'category': 'Hardware Issues', 'tags': 'Lapto...  \n","2  {'here are some sub-tasks to assist me in furt...  \n","3  {'sure, i can help you with that! based on the...  \n","4  {'category': 'Technical Issues', 'tags': 'Smar...  \n"]}],"source":["data['llama_response_normalized'] = data['llama_response_parsed'].apply(normalize_llama_response)\n","\n","print(data.head())"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAxO8hy1UoYFCiHnjq0pEH","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"047fc9dc42044a09b524f032c61f6e38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"12b2a94d9f554cc4a1a2bcee6bedec52":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"145639afd05944b0978a932a9833c738":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4066d046bbcd468796afd4c81d361d8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"51160d84d8054e5fa8bc717cc8a6fae9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7adc83d68d0a4f5fac68c06d4068a291":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_12b2a94d9f554cc4a1a2bcee6bedec52","placeholder":"​","style":"IPY_MODEL_4066d046bbcd468796afd4c81d361d8c","value":"llama-2-13b-chat.Q5_K_M.gguf: 100%"}},"86e670e1428648208656b980303b0b9a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_51160d84d8054e5fa8bc717cc8a6fae9","max":9229924224,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb8f1e445d884165b4702ca96ca945a0","value":9229924224}},"97079f3956444e1c8acbffa44952d2ae":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_145639afd05944b0978a932a9833c738","placeholder":"​","style":"IPY_MODEL_047fc9dc42044a09b524f032c61f6e38","value":" 9.23G/9.23G [01:02&lt;00:00, 238MB/s]"}},"cb8f1e445d884165b4702ca96ca945a0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2aff51cf4374a86aa48008ba223d505":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e1eb7a8885f74a168af943fa0fc136b2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7adc83d68d0a4f5fac68c06d4068a291","IPY_MODEL_86e670e1428648208656b980303b0b9a","IPY_MODEL_97079f3956444e1c8acbffa44952d2ae"],"layout":"IPY_MODEL_d2aff51cf4374a86aa48008ba223d505"}}}}},"nbformat":4,"nbformat_minor":0}
